{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the required packages\n",
    "%pip install geopandas pandas folium requests tqdm matplotlib xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import geopandas\n",
    "import re\n",
    "import pandas as pd\n",
    "import folium\n",
    "import requests\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import xlrd\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The code below will gather bus/MRT geospatial data needed for our project by making API Calls to LTA DataMall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set an environmental variable named LTA_Key to store your API key for the LTA DataMall\n",
    "# Query the LTA DataMall API for the bus routes data\n",
    "all_data = []\n",
    "\n",
    "skip = 0\n",
    "\n",
    "resource_url = \"https://datamall2.mytransport.sg/ltaodataservice/BusRoutes\"\n",
    "headers = {\n",
    "    'AccountKey': os.getenv(\"LTA_Key\"),\n",
    "    'accept': \"application/json\"\n",
    "}\n",
    "\n",
    "# API only allows 500 records to be retrieved at a time, hence a while loop is used to retrieve all records\n",
    "while True:\n",
    "    url = f\"{resource_url}?$skip={skip}\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        break\n",
    "    \n",
    "    res_list = response.json()\n",
    "    data = res_list.get('value', [])\n",
    "    \n",
    "    if not data:\n",
    "        break\n",
    "    \n",
    "    all_data.extend(data)\n",
    "    skip += 500\n",
    "\n",
    "# Convert the collected data to a DataFrame\n",
    "df = pd.json_normalize(all_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('data/bus_routes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the LTA DataMall API for the bus stops data (Can be merged with bus_routes data)\n",
    "all_data1 = []\n",
    "\n",
    "skip1 = 0\n",
    "\n",
    "resource_url1 = \"https://datamall2.mytransport.sg/ltaodataservice/BusStops\"\n",
    "headers = {\n",
    "    'AccountKey': os.getenv(\"LTA_Key\"),\n",
    "    'accept': \"application/json\"\n",
    "}\n",
    "\n",
    "# API only allows 500 records to be retrieved at a time, hence a while loop is used to retrieve all records\n",
    "while True:\n",
    "    url = f\"{resource_url1}?$skip={skip1}\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        break\n",
    "    \n",
    "    res_list = response.json()\n",
    "    data = res_list.get('value', [])\n",
    "    \n",
    "    if not data:\n",
    "        break\n",
    "    \n",
    "    all_data1.extend(data)\n",
    "    skip1 += 500\n",
    "\n",
    "# Convert the collected data to a DataFrame\n",
    "df1 = pd.json_normalize(all_data1)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df1.to_csv('data/bus_stops.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the LTA DataMall API for the passenger volume by bus stop\n",
    "all_data2 = []\n",
    "\n",
    "skip2 = 0\n",
    "\n",
    "resource_url2 = \"https://datamall2.mytransport.sg/ltaodataservice/PV/Bus\"\n",
    "headers = {\n",
    "    'AccountKey': os.getenv(\"LTA_Key\"),\n",
    "    'accept': \"application/json\"\n",
    "}\n",
    "\n",
    "# API only allows 500 records to be retrieved at a time, hence a while loop is used to retrieve all records\n",
    "while True:\n",
    "    url = f\"{resource_url2}?$skip={skip2}\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        break\n",
    "    \n",
    "    res_list = response.json()\n",
    "    data = res_list.get('value', [])\n",
    "    \n",
    "    if not data:\n",
    "        break\n",
    "    \n",
    "    all_data2.extend(data)\n",
    "    skip2 += 500\n",
    "\n",
    "# Convert the collected data to a DataFrame\n",
    "df2 = pd.json_normalize(all_data2)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df2.to_csv('data/passenger_vol_bus_stops.csv', index=False)\n",
    "\n",
    "# Note that for this API Call, the output is a hyperlink where you will need to download the files manually (File Name: transport_node_bus_202408.csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the LTA DataMall API for the passenger volume by origin-destination bus stop\n",
    "all_data3 = []\n",
    "\n",
    "skip3 = 0\n",
    "\n",
    "resource_url3 = \"https://datamall2.mytransport.sg/ltaodataservice/PV/ODBus\"\n",
    "headers = {\n",
    "    'AccountKey': os.getenv(\"LTA_Key\"),\n",
    "    'accept': \"application/json\"\n",
    "}\n",
    "\n",
    "# API only allows 500 records to be retrieved at a time, hence a while loop is used to retrieve all records\n",
    "while True:\n",
    "    url = f\"{resource_url3}?$skip={skip3}\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        break\n",
    "    \n",
    "    res_list = response.json()\n",
    "    data = res_list.get('value', [])\n",
    "    \n",
    "    if not data:\n",
    "        break\n",
    "    \n",
    "    all_data3.extend(data)\n",
    "    skip3 += 500\n",
    "\n",
    "# Convert the collected data to a DataFrame\n",
    "df3 = pd.json_normalize(all_data3)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df3.to_csv('data/passenger_vol_OD_bus_stops.csv', index=False)\n",
    "\n",
    "# Note that for this API Call, the output is a hyperlink where you will need to download the files manually (File Name: origin_destination_bus_202408)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the LTA DataMall API for the passenger volume by train station\n",
    "all_data4 = []\n",
    "\n",
    "skip4 = 0\n",
    "\n",
    "resource_url4 = \"https://datamall2.mytransport.sg/ltaodataservice/PV/Train\"\n",
    "headers = {\n",
    "    'AccountKey': os.getenv(\"LTA_Key\"),\n",
    "    'accept': \"application/json\"\n",
    "}\n",
    "\n",
    "# API only allows 500 records to be retrieved at a time, hence a while loop is used to retrieve all records\n",
    "while True:\n",
    "    url = f\"{resource_url4}?$skip={skip4}\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        break\n",
    "    \n",
    "    res_list = response.json()\n",
    "    data = res_list.get('value', [])\n",
    "    \n",
    "    if not data:\n",
    "        break\n",
    "    \n",
    "    all_data4.extend(data)\n",
    "    skip4 += 500\n",
    "\n",
    "# Convert the collected data to a DataFrame\n",
    "df4 = pd.json_normalize(all_data4)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df4.to_csv('data/passenger_vol_train.csv', index=False)\n",
    "\n",
    "# Note that for this API Call, the output is a hyperlink where you will need to download the files manually (File Name: transport_node_train_202408.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the LTA DataMall API for the passenger volume by origin-destination MRT Station\n",
    "all_data5 = []\n",
    "\n",
    "skip5 = 0\n",
    "\n",
    "resource_url5 = \"https://datamall2.mytransport.sg/ltaodataservice/PV/ODTrain\"\n",
    "headers = {\n",
    "    'AccountKey': os.getenv(\"LTA_Key\"),\n",
    "    'accept': \"application/json\"\n",
    "}\n",
    "\n",
    "# API only allows 500 records to be retrieved at a time, hence a while loop is used to retrieve all records\n",
    "while True:\n",
    "    url = f\"{resource_url5}?$skip={skip5}\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        break\n",
    "    \n",
    "    res_list = response.json()\n",
    "    data = res_list.get('value', [])\n",
    "    \n",
    "    if not data:\n",
    "        break\n",
    "    \n",
    "    all_data5.extend(data)\n",
    "    skip5 += 500\n",
    "\n",
    "# Convert the collected data to a DataFrame\n",
    "df5 = pd.json_normalize(all_data5)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df5.to_csv('data/passenger_vol_OD_MRT_stations.csv', index=False)\n",
    "\n",
    "# Note that for this API Call, the output is a hyperlink where you will need to download the files manually (File Name: origin_destination_train_202408.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is our code to read in the datasets obtained from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_stops = pd.read_csv('data/bus_stops.csv') # All Bus Stops in Singapore Long and Lat data \n",
    "bus_routes = pd.read_csv('data/bus_routes.csv') # Bus routes for each bus service (Can be merged with bus_stops data)\n",
    "\n",
    "passenger_vol_bus_stops = pd.read_csv('data/transport_node_bus_202408.csv') # Passenger volume for each bus stop\n",
    "passenger_vol_OD_bus_stops = pd.read_csv('data/origin_destination_bus_202408.csv') # Passenger volume for each origin-destination bus stop\n",
    "\n",
    "passenger_vol_train = pd.read_csv('data/transport_node_train_202408.csv') # Passenger volume for each train station\n",
    "passenger_vol_OD_MRT_stations = pd.read_csv('data/origin_destination_train_202408.csv') # Passenger volume for each origin-destination train station\n",
    "\n",
    "train_station_code = pd.read_excel('data/Train Station Codes and Chinese Names.xls') # Train station code for each train station"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
